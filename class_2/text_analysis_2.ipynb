{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEr7nLCk9mF_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "grimms_folder = \"drive/MyDrive/grimms\"\n"
      ],
      "metadata": {
        "id": "RUoT-I3m9_dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import string\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "D3TE_tVu9ttp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a19bf0d-1364-4154-c8d1-d321bae4f66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the text file\n",
        "\n",
        "rapunzel = open(os.path.join(grimms_folder, \"rapunzel.txt\"), encoding=\"utf-8\").read()\n",
        "\n",
        "tokens = word_tokenize(rapunzel)"
      ],
      "metadata": {
        "id": "Gvus3So5Iajj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "JBYqaHVW-LX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking is pronouns are stopwords or not\n",
        "\n",
        "stopwords = stopwords.words(\"english\")\n",
        "\n",
        "if \"her\" in stopwords:\n",
        "  print(\"It's a stopword\")\n",
        "else:\n",
        "  print(\"It's not a stopword\")"
      ],
      "metadata": {
        "id": "poAzYifH5UKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning tokens of punctuation, and making all lowercase\n",
        "\n",
        "punctuation = list(string.punctuation)\n",
        "\n",
        "punctuation.append(\"‘\")\n",
        "punctuation.append(\"’\")\n",
        "\n",
        "for token in tokens:\n",
        "  if token in punctuation:\n",
        "    tokens.remove(token)\n",
        "\n",
        "tokens = [token.lower() for token in tokens]"
      ],
      "metadata": {
        "id": "0j8539aX4-H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating frequency and male and female pronouns\n",
        "\n",
        "female_pronouns = [\"she\", \"her\", \"hers\", \"herself\"]\n",
        "male_pronouns = [\"he\", \"him\", \"his\", \"himself\"]\n",
        "\n",
        "female_pronoun_count = 0\n",
        "\n",
        "for x in female_pronouns:\n",
        "  for y in tokens:\n",
        "    if x == y:\n",
        "      female_pronoun_count += 1\n",
        "\n",
        "male_pronoun_count = 0\n",
        "\n",
        "for x in male_pronouns:\n",
        "  for y in tokens:\n",
        "     if x == y:\n",
        "      male_pronoun_count += 1\n",
        "\n",
        "relative_female_freq = female_pronoun_count / len(tokens)\n",
        "relative_male_freq = male_pronoun_count / len(tokens)\n",
        "\n",
        "print(\"The relative frequency of female pronouns is: \" + str(relative_female_freq))\n",
        "print(\"The relative frequency of male pronouns is: \" + str(relative_male_freq))"
      ],
      "metadata": {
        "id": "3U_oxEDQxIwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis--Bag of Words Approach"
      ],
      "metadata": {
        "id": "9HGfc9GjyRvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "5B_0TlIUx11A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241639bc-20b0-4eb8-9bbb-ea91e4c37752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the VADER sentiment analyzer tool\n",
        "\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "#Assigning the VADER lexicon to a variable\n",
        "\n",
        "vader_lexicon = list(sentiment_analyzer.lexicon.items())\n",
        "\n",
        "print(vader_lexicon[2000])\n",
        "\n"
      ],
      "metadata": {
        "id": "_fX_jZn2yqs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4e0beb-ec98-4b02-e8ad-bb521a271615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('destructive', -3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating sentiment scores for Rapunzel\n",
        "\n",
        "rapunzel = open(os.path.join(grimms_folder, \"rapunzel.txt\"), encoding=\"utf-8\").read()\n",
        "\n",
        "sentiment_scores = sentiment_analyzer.polarity_scores(rapunzel)\n",
        "print(sentiment_scores)"
      ],
      "metadata": {
        "id": "f72IlSwoyqmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ea92c8-8ae8-497e-8472-74077d5497ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.113, 'neu': 0.782, 'pos': 0.106, 'compound': -0.9096}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_scores[\"compound\"]"
      ],
      "metadata": {
        "id": "L0-T8SKq03qX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4d076c-2e80-4d56-ee81-c413105ed7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.9096"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating sentiment scores for all text files in a folder\n",
        "\n",
        "results = []\n",
        "\n",
        "for file in os.listdir(grimms_folder):\n",
        "  if file.endswith(\".txt\"):\n",
        "\n",
        "    file_path = os.path.join(grimms_folder, file)\n",
        "\n",
        "    text = open(file_path, encoding=\"utf-8\").read()\n",
        "    sentiment_scores = sentiment_analyzer.polarity_scores(text)\n",
        "    compound_score = sentiment_scores[\"compound\"]\n",
        "    results.append({\"file\": file, \"sentiment\": compound_score})\n",
        "\n"
      ],
      "metadata": {
        "id": "dFdKlF3k1gJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing results to a dataframe\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "df_results.sort_values(\"sentiment\", ascending=False)"
      ],
      "metadata": {
        "id": "g08VtRLNkmON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cpn4s1LvzLQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IS1WpUPgzpLA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}